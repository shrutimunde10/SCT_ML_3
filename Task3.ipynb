{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1mMO6fkMaUnRNOwc-cNKdmDiOD0-RxTek",
      "authorship_tag": "ABX9TyORIxpy1t/IPmd/vqRllI+3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrutimunde10/SCT_ML_3/blob/main/Task3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9O4xHBk8Uh0",
        "outputId": "44afb079-482e-495b-c7be-a93e39c193ce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the uploaded zip file\n",
        "zip_file_path = '/content/drive/MyDrive/Colab Notebooks/AIML datasets/Task 3 dataset (1).zip'\n",
        "extract_dir = '/content/drive/MyDrive/Colab Notebooks/AIML datasets/Task 3 dataset/dogs_cats_sample_1000'\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# List the extracted files and directories\n",
        "os.listdir(extract_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsD4QEQc9OzF",
        "outputId": "2ec44efe-48e9-4cdc-c772-094f4ba89bec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['valid', 'dogs_cats_sample_1000', 'train']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the extracted dataset directory\n",
        "dataset_path = os.path.join(extract_dir, 'dogs_cats_sample_1000')\n",
        "\n",
        "# List the contents of the dataset directory\n",
        "os.listdir(dataset_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEmrS2wH-DX-",
        "outputId": "d387b619-d2ef-4f54-92fb-15cfd808c97d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'valid', 'dogs_cats_sample_1000']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the train directory\n",
        "train_dir = os.path.join(dataset_path, 'train')\n",
        "\n",
        "# List the contents of the train directory\n",
        "os.listdir(train_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZiIIhKb_EBn",
        "outputId": "6894e6e5-1930-4c20-8f76-13ac82b1b938"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cats', 'dogs']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import cv2\n",
        "\n",
        "# Parameters for preprocessing\n",
        "IMG_SIZE = 128  # Resize images to 128x128\n",
        "\n",
        "# Helper function to load images and labels\n",
        "def load_images_from_directory(directory, label, img_size):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for file in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, file)\n",
        "        if file.endswith(('.jpg', '.png', '.jpeg')):  # Ensure valid image files\n",
        "            img = load_img(file_path, target_size=(img_size, img_size))\n",
        "            img_array = img_to_array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
        "            images.append(img_array)\n",
        "            labels.append(label)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load images from cats and dogs folders\n",
        "cats_dir = os.path.join(train_dir, 'cats')\n",
        "dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "cat_images, cat_labels = load_images_from_directory(cats_dir, 0, IMG_SIZE)  # Label 0 for cats\n",
        "dog_images, dog_labels = load_images_from_directory(dogs_dir, 1, IMG_SIZE)  # Label 1 for dogs\n",
        "\n",
        "# Combine and shuffle the dataset\n",
        "X = np.concatenate([cat_images, dog_images], axis=0)\n",
        "y = np.concatenate([cat_labels, dog_labels], axis=0)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Check the dataset shapes\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GlMMj-G_JkR",
        "outputId": "975a0eb0-0afb-4ff6-9307-dbbb1bdff3df"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1600, 128, 128, 3), (400, 128, 128, 3), (1600,), (400,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusted helper function to use OpenCV for image loading and resizing\n",
        "def load_images_opencv(directory, label, img_size):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for file in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, file)\n",
        "        if file.endswith(('.jpg', '.png', '.jpeg')):  # Ensure valid image files\n",
        "            img = cv2.imread(file_path)  # Load image with OpenCV\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "            img = cv2.resize(img, (img_size, img_size))  # Resize to target size\n",
        "            img = img / 255.0  # Normalize pixel values to [0, 1]\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Reload images using OpenCV\n",
        "cat_images, cat_labels = load_images_opencv(cats_dir, 0, IMG_SIZE)  # Label 0 for cats\n",
        "dog_images, dog_labels = load_images_opencv(dogs_dir, 1, IMG_SIZE)  # Label 1 for dogs\n",
        "\n",
        "# Combine and shuffle the dataset\n",
        "X = np.concatenate([cat_images, dog_images], axis=0)\n",
        "y = np.concatenate([cat_labels, dog_labels], axis=0)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Check the dataset shapes\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkFPUiHU_M9F",
        "outputId": "57e1a67d-963b-4bf7-b9e4-e2486e681a90"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1600, 128, 128, 3), (400, 128, 128, 3), (1600,), (400,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefine paths for cats and dogs directories\n",
        "cats_dir = os.path.join(train_dir, 'cats')\n",
        "dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Reload images using OpenCV\n",
        "cat_images, cat_labels = load_images_opencv(cats_dir, 0, IMG_SIZE)  # Label 0 for cats\n",
        "dog_images, dog_labels = load_images_opencv(dogs_dir, 1, IMG_SIZE)  # Label 1 for dogs\n",
        "\n",
        "# Combine and shuffle the dataset\n",
        "X = np.concatenate([cat_images, dog_images], axis=0)\n",
        "y = np.concatenate([cat_labels, dog_labels], axis=0)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Check the dataset shapes\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJqZHurB_Qad",
        "outputId": "c8833f97-2dba-42e8-ee63-cb262165cc8c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1600, 128, 128, 3), (400, 128, 128, 3), (1600,), (400,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefine the image size and paths\n",
        "IMG_SIZE = 128  # Resize images to 128x128 pixels\n",
        "cats_dir = os.path.join(train_dir, 'cats')\n",
        "dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Reload images using OpenCV\n",
        "cat_images, cat_labels = load_images_opencv(cats_dir, 0, IMG_SIZE)  # Label 0 for cats\n",
        "dog_images, dog_labels = load_images_opencv(dogs_dir, 1, IMG_SIZE)  # Label 1 for dogs\n",
        "\n",
        "# Combine and shuffle the dataset\n",
        "X = np.concatenate([cat_images, dog_images], axis=0)\n",
        "y = np.concatenate([cat_labels, dog_labels], axis=0)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Check the dataset shapes\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqpj8Ep5_W5W",
        "outputId": "f06693cd-6da5-4e25-cd73-ab29cbd4cfbe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1600, 128, 128, 3), (400, 128, 128, 3), (1600,), (400,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-importing OpenCV for image processing\n",
        "import cv2\n",
        "\n",
        "# Reload images using OpenCV\n",
        "cat_images, cat_labels = load_images_opencv(cats_dir, 0, IMG_SIZE)  # Label 0 for cats\n",
        "dog_images, dog_labels = load_images_opencv(dogs_dir, 1, IMG_SIZE)  # Label 1 for dogs\n",
        "\n",
        "# Combine and shuffle the dataset\n",
        "X = np.concatenate([cat_images, dog_images], axis=0)\n",
        "y = np.concatenate([cat_labels, dog_labels], axis=0)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Check the dataset shapes\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jABiAszU_d6h",
        "outputId": "2d09bf67-44d0-439c-f510-876cdfeb47fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1600, 128, 128, 3), (400, 128, 128, 3), (1600,), (400,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator to load images in batches\n",
        "def image_generator(directory, label, img_size, batch_size=100, dtype=np.float32):\n",
        "    files = [f for f in os.listdir(directory) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "    for i in range(0, len(files), batch_size):\n",
        "        batch_files = files[i:i+batch_size]\n",
        "        images = []\n",
        "        labels = []\n",
        "        for file in batch_files:\n",
        "            file_path = os.path.join(directory, file)\n",
        "            img = cv2.imread(file_path)  # Load image with OpenCV\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "            img = cv2.resize(img, (img_size, img_size))  # Resize to target size\n",
        "            img = img.astype(dtype) / 255.0  # Normalize pixel values to [0, 1]\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "        yield np.array(images, dtype=dtype), np.array(labels, dtype=np.int8)\n",
        "\n",
        "# Example usage to load batches of images\n",
        "batch_size = 100\n",
        "\n",
        "# Load the first batch of cats and dogs\n",
        "cat_batch_gen = image_generator(cats_dir, 0, IMG_SIZE, batch_size=batch_size)\n",
        "dog_batch_gen = image_generator(dogs_dir, 1, IMG_SIZE, batch_size=batch_size)\n",
        "\n",
        "# Fetch the first batches\n",
        "cat_images_batch, cat_labels_batch = next(cat_batch_gen)\n",
        "dog_images_batch, dog_labels_batch = next(dog_batch_gen)\n",
        "\n",
        "# Check the shapes of the first batches\n",
        "cat_images_batch.shape, dog_images_batch.shape, cat_labels_batch.shape, dog_labels_batch.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns-Fxx7A_agU",
        "outputId": "d550e1db-9fb3-4eda-cc02-96a7d3a324c5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 128, 128, 3), (100, 128, 128, 3), (100,), (100,))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import hog\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Parameters\n",
        "IMG_SIZE = 128  # Resize images to 128x128\n",
        "HOG_PARAMS = {\n",
        "    'orientations': 9,\n",
        "    'pixels_per_cell': (8, 8),\n",
        "    'cells_per_block': (2, 2),\n",
        "    'block_norm': 'L2-Hys'\n",
        "}\n",
        "\n",
        "# Helper function to load images in batches\n",
        "def load_images_with_hog(directory, label, img_size, batch_size=100):\n",
        "    files = [f for f in os.listdir(directory) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "    features, labels = [], []\n",
        "    for i, file in enumerate(files):\n",
        "        file_path = os.path.join(directory, file)\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
        "        img = cv2.resize(img, (img_size, img_size))  # Resize to target size\n",
        "        # Extract HOG features\n",
        "        hog_features = hog(img, **HOG_PARAMS)\n",
        "        features.append(hog_features)\n",
        "        labels.append(label)\n",
        "        if (i + 1) % batch_size == 0 or (i + 1) == len(files):\n",
        "            yield np.array(features), np.array(labels)\n",
        "            features, labels = [], []\n",
        "\n",
        "# Load cats and dogs data\n",
        "cats_dir = \"/content/drive/MyDrive/Colab Notebooks/AIML datasets/Task 3 dataset/dogs_cats_sample_1000/dogs_cats_sample_1000/train/cats\"\n",
        "dogs_dir = \"/content/drive/MyDrive/Colab Notebooks/AIML datasets/Task 3 dataset/dogs_cats_sample_1000/dogs_cats_sample_1000/train/dogs\"\n",
        "\n",
        "cat_generator = load_images_with_hog(cats_dir, 0, IMG_SIZE)\n",
        "dog_generator = load_images_with_hog(dogs_dir, 1, IMG_SIZE)\n",
        "\n",
        "X, y = [], []\n",
        "\n",
        "# Process all cat images\n",
        "for features, labels in cat_generator:\n",
        "    X.append(features)\n",
        "    y.append(labels)\n",
        "\n",
        "# Process all dog images\n",
        "for features, labels in dog_generator:\n",
        "    X.append(features)\n",
        "    y.append(labels)\n",
        "\n",
        "# Combine and shuffle the dataset\n",
        "X = np.vstack(X)\n",
        "y = np.hstack(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Train an SVM classifier\n",
        "svm = SVC(kernel='linear', probability=True, random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=['Cat', 'Dog'])\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLRQxjxeAxb1",
        "outputId": "b57d70e0-1307-4a85-caad-3660090d6866"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.65\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         Cat       0.64      0.69      0.66       200\n",
            "         Dog       0.66      0.61      0.64       200\n",
            "\n",
            "    accuracy                           0.65       400\n",
            "   macro avg       0.65      0.65      0.65       400\n",
            "weighted avg       0.65      0.65      0.65       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on a single image (example)\n",
        "def predict_image():\n",
        "    img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/AIML datasets/Task 3 dataset/dogs_cats_sample_1000/dogs_cats_sample_1000/train/cats/cat.10160.jpg', cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    hog_features = hog(img, **HOG_PARAMS).reshape(1, -1)\n",
        "    prediction = svm.predict(hog_features)\n",
        "    return \"Dog\" if prediction[0] == 1 else \"Cat\"\n",
        "\n",
        "# Example usage\n",
        "#print(predict_image(\"/content/drive/MyDrive/Colab Notebooks/AIML datasets/Task 3 dataset/dogs_cats_sample_1000/dogs_cats_sample_1000/train/cats/cat.10161.jpg\"))\n"
      ],
      "metadata": {
        "id": "M9wlG5EDEII7"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}